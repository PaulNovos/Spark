{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5548dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/14 07:31:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('word_count').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b758b95",
   "metadata": {},
   "source": [
    "1 Выберите 15 стран с наибольшим процентом переболевших на 31 марта (в выходящем датасете необходимы колонки: iso_code, страна, процент переболевших)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47f694e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:>                                                         (0 + 4) / 4]\r",
      "\r",
      "[Stage 28:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+------------------+\n",
      "|iso_code|     location|   percent_of_sick|\n",
      "+--------+-------------+------------------+\n",
      "|     AND|      Andorra|15.543907331909661|\n",
      "|     MNE|   Montenegro|14.523725364693293|\n",
      "|     CZE|      Czechia|14.308848404077997|\n",
      "|     SMR|   San Marino|13.937179562732041|\n",
      "|     SVN|     Slovenia|10.370805779121204|\n",
      "|     LUX|   Luxembourg| 9.847342390123583|\n",
      "|     ISR|       Israel| 9.625106044786802|\n",
      "|     USA|United States| 9.203010995860707|\n",
      "|     SRB|       Serbia| 8.826328557933492|\n",
      "|     BHR|      Bahrain| 8.488860079114566|\n",
      "|     PAN|       Panama| 8.228739065460761|\n",
      "|     PRT|     Portugal| 8.058699735120369|\n",
      "|     EST|      Estonia| 8.022681579659551|\n",
      "|     SWE|       Sweden| 7.969744347858805|\n",
      "|     LTU|    Lithuania| 7.938864728274825|\n",
      "+--------+-------------+------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_1 = spark.read.csv('owid-covid-data.csv', header=True).select(\"iso_code\", \"date\", \"location\", \"total_cases\", \"population\")\n",
    "\n",
    "df_1\\\n",
    ".select('iso_code', 'location', ((df_1.total_cases/df_1.population)*100).alias('percent_of_sick'))\\\n",
    ".where(col('date') == '2021-03-31')\\\n",
    ".orderBy(col('percent_of_sick').desc())\\\n",
    ".show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e9714",
   "metadata": {},
   "source": [
    "2 Top 10 стран с максимальным зафиксированным кол-вом новых случаев за последнюю неделю марта 2021 в отсортированном порядке по убыванию\n",
    "(в выходящем датасете необходимы колонки: число, страна, кол-во новых случаев)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0dcc86dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 144:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------+\n",
      "|      date|     location|new_cases|\n",
      "+----------+-------------+---------+\n",
      "|2021-03-25|       Brazil| 100158.0|\n",
      "|2021-03-31|       Brazil|  90638.0|\n",
      "|2021-03-27|       Brazil|  85948.0|\n",
      "|2021-03-30|       Brazil|  84494.0|\n",
      "|2021-03-26|       Brazil|  84245.0|\n",
      "|2021-03-26|United States|  77321.0|\n",
      "|2021-03-31|        India|  72330.0|\n",
      "|2021-03-29|United States|  69429.0|\n",
      "|2021-03-28|        India|  68020.0|\n",
      "|2021-03-25|United States|  67465.0|\n",
      "+----------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2 = spark.read.csv('owid-covid-data.csv', header=True, inferSchema=True).select(\"iso_code\", \"date\", \"location\", \"new_cases\")\n",
    "\n",
    "df_2\\\n",
    ".select('date', 'location', 'new_cases')\\\n",
    ".where((col('date') > '2021-03-24')\\\n",
    "       & (col('date') <= '2021-03-31')\\\n",
    "       & (~col('location').isin('North America', 'South America','World','Europe', 'European Union', 'Asia')))\\\n",
    ".orderBy(col('new_cases').desc()) \\\n",
    ".show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b10778",
   "metadata": {},
   "source": [
    "3 Посчитайте изменение случаев относительно предыдущего дня в России за последнюю неделю марта 2021. (например: в россии вчера было 9150 , сегодня 8763, итог: -387) (в выходящем датасете необходимы колонки: число, кол-во новых случаев вчера, кол-во новых случаев сегодня, дельта)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4cf2076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:====================================>                 (134 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------+------+\n",
      "|      date|previous_cases|new_cases| delta|\n",
      "+----------+--------------+---------+------+\n",
      "|2021-03-25|        8769.0|   9128.0| 359.0|\n",
      "|2021-03-26|        9128.0|   9073.0| -55.0|\n",
      "|2021-03-27|        9073.0|   8783.0|-290.0|\n",
      "|2021-03-28|        8783.0|   8979.0| 196.0|\n",
      "|2021-03-29|        8979.0|   8589.0|-390.0|\n",
      "|2021-03-30|        8589.0|   8162.0|-427.0|\n",
      "|2021-03-31|        8162.0|   8156.0|  -6.0|\n",
      "+----------+--------------+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:=============================================>        (169 + 5) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "df_3 = spark.read.csv('owid-covid-data.csv', header=True, inferSchema=True)\\\n",
    ".select(\"iso_code\", col(\"date\").cast(DateType()), \"location\", \"new_cases\")\\\n",
    ".where((col('location') == 'Russia'))\n",
    "\n",
    "w = Window().partitionBy('location').orderBy('date')\n",
    "\n",
    "df_3\\\n",
    ".select('date',\\\n",
    "        (lag('new_cases').over(w)).alias('previous_cases'),\\\n",
    "        'new_cases',\\\n",
    "        (df_3.new_cases - lag('new_cases').over(w)).alias('delta'))\\\n",
    ".where((col('date') > '2021-03-24') & (col('date') <= '2021-03-31'))\\\n",
    ".orderBy('date')\\\n",
    ".show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
